{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfFnU5KHMucK",
    "outputId": "e541ddc9-bb71-4de5-e86d-3638d8b5f5b5"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers einops accelerate langchain bitsandbytes\n",
    "!pip install -qqq openai\n",
    "!pip install -Uqqq chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MICYM0wXiOh1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "\n",
    "import langchain\n",
    "import chromadb\n",
    "import transformers\n",
    "import openai\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVCHolcqM1CU",
    "outputId": "30884e3d-8b78-4957-9012-04b736b25e60"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f47vPJ1IiJzP"
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"INSERT_YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "referenced_widgets": [
      "396550fe2345431489c31c425a87f52e",
      "9df7bbe6351c4e868a53faf0cfcfce2b",
      "370c49570b2544a49591858580bc4e78",
      "3f68546181a6474e83084c08d0817f37",
      "d9853753c3c741e08e2d4142647a8637",
      "1684a351471445ec895dc37b353364ea",
      "88485a797ed4446f93b89f053a38f120",
      "35a4b4534ce348fcaf63b4a70f4e1485",
      "ae1b58e923e14fe794c15f6e763a2506",
      "d0c5e4b7dae1430e9207211dfeac4730",
      "c14eeec4a00842e6b57c439fc4555586"
     ]
    },
    "id": "D8MP3fE2NPmI",
    "outputId": "59a9ce38-51f0-4666-8d8e-712daff79529"
   },
   "outputs": [],
   "source": [
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "      \"text-generation\", \n",
    "      model=model,\n",
    "      tokenizer=tokenizer,\n",
    "      torch_dtype=torch.bfloat16,\n",
    "      trust_remote_code=True,\n",
    "      device_map=\"auto\",\n",
    "      max_length=1000,\n",
    "      do_sample=True,\n",
    "      top_k=10,\n",
    "      num_return_sequences=1,\n",
    "      eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2rxa4-1fi9qb",
    "outputId": "afa22357-8157-4b6e-c43b-fceb84074368"
   },
   "outputs": [],
   "source": [
    "# Load documents locally as CSV\n",
    "loader = CSVLoader('/content/sample_data/Frangrances-Dataset.csv')\n",
    "docs = loader.load()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "730BC0bYCpnj"
   },
   "outputs": [],
   "source": [
    "# Split document into text chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Pd7I2rBcCtSL"
   },
   "outputs": [],
   "source": [
    "# Initialize the open-source embedding function, default: text-embedding-ada-002\n",
    "embedding_function = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "spY4Jz-jCuoo"
   },
   "outputs": [],
   "source": [
    "# Load it into ChromaDB\n",
    "db = Chroma.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "yR9DL4RqnN8A"
   },
   "outputs": [],
   "source": [
    "#Design Prompt Template\n",
    "template = \"\"\"You are a customer service chatbot for an online perfume company called Fragrances International.\n",
    "\n",
    "{context}\n",
    "\n",
    "Answer the customer's questions only using the source data provided. If you are unsure, say \"I don't know, please call our customer support\". Use engaging, courteous, and professional language similar to a customer representative.\n",
    "Keep your answers concise.\n",
    "\n",
    "Question:\n",
    "\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "g9xVFRrOCyX7"
   },
   "outputs": [],
   "source": [
    "#Intiliaze prompt using prompt template via langchain\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\"])\n",
    "print(\n",
    "    prompt.format(\n",
    "        context = \"A customer is on the perfume company website and wants to chat with the website chatbot.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gPLs4H0CkG1L"
   },
   "outputs": [],
   "source": [
    "#Chain to have all components together and query the LLM\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(search_kwargs={\"k\": 1}),\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xDIhIGCWCL27"
   },
   "outputs": [],
   "source": [
    "# Formatted printing\n",
    "def print_response(response: str):\n",
    "    print(\"\\n\".join(textwrap.wrap(response, width=80)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CyLzPoPDkJPC"
   },
   "outputs": [],
   "source": [
    "#Running chain through LLM with query\n",
    "query = \"What types of perfumes do you sell?\"\n",
    "response = chain.run(query)\n",
    "print_response(response)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
